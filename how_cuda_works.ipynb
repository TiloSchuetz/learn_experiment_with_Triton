{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb355280",
   "metadata": {},
   "source": [
    "### How CUDA and GPU parallelization works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8c1a1",
   "metadata": {},
   "source": [
    "##### Summary of key terms\n",
    "\n",
    "**FLOPS** floating-point operations per second\n",
    "-> measures the throughput of a GPU. Theoretical peak throughput = (number of cores) × (instructions per core per cycle) × (clock frequency)\n",
    "\n",
    "**core**: execution unit capable of performing operations\n",
    "\n",
    "**clock cycle**: one “tick” of the processor’s clock\n",
    "\n",
    "**fused multiply-add (FMA)**: some GPUs can do an addition and multiplication within on clock cycle\n",
    "\n",
    "**Clock Frequency**: measured in Heartz = cycles per second. 1.5 GHz = 1.5 billion cycles per second\n",
    "\n",
    "**Memory Bandwidth**: rate at which data can be transferred between GPU memory (VRAM) and GPU compute units. Usually measures in GB/S (gigabytes per second)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f5670",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa89e9df",
   "metadata": {},
   "source": [
    "![Architecture comparison CPU vs. GPU](./images/gpu-devotes-more-transistors-to-data-processing.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
